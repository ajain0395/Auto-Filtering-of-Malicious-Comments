{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import seaborn as seab\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "def add_feature(X, feature_to_add):\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('testtest.csv')\n",
    "#print train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments that are non toxic:  143346\n",
      "Percentage of comments that are non toxic:\n",
      "89.8321123512\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print ('comments that are non toxic: '),\n",
    "nontoxic=len(train_df[(train_df['toxic']==0) & (train_df['severe_toxic']==0) & (train_df['obscene']==0) & (train_df['threat']== 0) & (train_df['insult']==0) & (train_df['identity_hate']==0)])\n",
    "print nontoxic \n",
    "print ('Percentage of comments that are non toxic:')\n",
    "print (float(nontoxic)/len(train_df))*100\n",
    "\n",
    "categories = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "train_comment = train_df.comment_text\n",
    "test_comment = test_df.comment_text\n",
    "#print test_comment.shape,train_comment.shape\n",
    "\n",
    "data = train_df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "#corr = data.astype(float).corr()\n",
    "#seab.heatmap(corr,linewidths=0.4,linecolor='white',annot=True)\n",
    "\n",
    "vect = TfidfVectorizer(max_features=4000,stop_words='english')\n",
    "train_vec = vect.fit_transform(train_comment)\n",
    "test_vec = vect.transform(test_comment)\n",
    "Zlist = {}\n",
    "for clas in categories:\n",
    "    Zlist[clas] = np.array(test_df[clas].tolist())\n",
    "\n",
    "    \n",
    "\n",
    "#print test_comment.shape,train_comment.shape\n",
    "#print train_vec.shape\n",
    "#Zlist = np.array(Zlist)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "logreg = LogisticRegression(C=12.0)\n",
    "nbmodel = MultinomialNB()\n",
    "#print Zlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#logistic regression with binary relevance\n",
      "Processing toxic\n",
      "Training accuracy : 0.9238644534058582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     57888\n",
      "           1       0.58      0.75      0.65      6090\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     63978\n",
      "   macro avg       0.77      0.85      0.80     63978\n",
      "weighted avg       0.93      0.92      0.93     63978\n",
      "\n",
      "Processing severe_toxic\n",
      "Training accuracy : 0.9923411172590578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63611\n",
      "           1       0.35      0.41      0.38       367\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.68      0.70      0.69     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "Processing obscene\n",
      "Training accuracy : 0.9626121479258495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     60287\n",
      "           1       0.68      0.67      0.67      3691\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     63978\n",
      "   macro avg       0.83      0.83      0.83     63978\n",
      "weighted avg       0.96      0.96      0.96     63978\n",
      "\n",
      "Processing threat\n",
      "Training accuracy : 0.9958110600518928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63767\n",
      "           1       0.36      0.35      0.35       211\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     63978\n",
      "   macro avg       0.68      0.67      0.68     63978\n",
      "weighted avg       1.00      1.00      1.00     63978\n",
      "\n",
      "Processing insult\n",
      "Training accuracy : 0.9612210447341274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     60551\n",
      "           1       0.66      0.56      0.61      3427\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     63978\n",
      "   macro avg       0.82      0.77      0.79     63978\n",
      "weighted avg       0.96      0.96      0.96     63978\n",
      "\n",
      "Processing identity_hate\n",
      "Training accuracy : 0.9901216043014787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     63266\n",
      "           1       0.59      0.38      0.46       712\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.79      0.69      0.73     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultantMatrix = []\n",
    "#resultantMatrix.append(['Labels','toxic','severe_toxic','obscene','threat','insult','identity_hate'])\n",
    "resultantMatrix.append(['Classification Technique','Average Accuracy'])\n",
    "matindex = 0\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "print \"#logistic regression with binary relevance\"\n",
    "\n",
    "\n",
    "matindex +=1\n",
    "resultantMatrix.append([])\n",
    "resultantMatrix[matindex].append(\"Logistic Regression Binary Relevance\")\n",
    "for classes in categories:\n",
    "    print 'Processing',classes\n",
    "    y = train_df[classes]\n",
    "    Z = Zlist[classes]\n",
    "    logreg.fit(train_vec, y)\n",
    "    y_pred_X = logreg.predict(test_vec)\n",
    "    accuracy=accuracy_score(Z, y_pred_X)\n",
    "    print 'Training accuracy :',accuracy\n",
    "    resultantMatrix[matindex].append(accuracy)\n",
    "    mett=metrics.classification_report(Z,y_pred_X)\n",
    "    print mett\n",
    "    #print logreg.predict_proba(test_vec)\n",
    "    test_y_prob = logreg.predict_proba(test_vec)[:,1]\n",
    "    #print test_y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Naive Bayes with binary relevance\n",
      "Processing toxic\n",
      "Training accuracy : 0.9346025196161181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     57888\n",
      "           1       0.69      0.56      0.62      6090\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     63978\n",
      "   macro avg       0.82      0.77      0.79     63978\n",
      "weighted avg       0.93      0.93      0.93     63978\n",
      "\n",
      "Processing severe_toxic\n",
      "Training accuracy : 0.9937634811966614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63611\n",
      "           1       0.45      0.37      0.41       367\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.72      0.69      0.70     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "Processing obscene\n",
      "Training accuracy : 0.9640188814905124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     60287\n",
      "           1       0.78      0.53      0.63      3691\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     63978\n",
      "   macro avg       0.87      0.76      0.80     63978\n",
      "weighted avg       0.96      0.96      0.96     63978\n",
      "\n",
      "Processing threat\n",
      "Training accuracy : 0.9967019913095126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63767\n",
      "           1       0.00      0.00      0.00       211\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     63978\n",
      "   macro avg       0.50      0.50      0.50     63978\n",
      "weighted avg       0.99      1.00      1.00     63978\n",
      "\n",
      "Processing insult\n",
      "Training accuracy : 0.9602363312388633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     60551\n",
      "           1       0.71      0.44      0.54      3427\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     63978\n",
      "   macro avg       0.84      0.72      0.76     63978\n",
      "weighted avg       0.95      0.96      0.96     63978\n",
      "\n",
      "Processing identity_hate\n",
      "Training accuracy : 0.9898871487073682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     63266\n",
      "           1       0.73      0.14      0.24       712\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.86      0.57      0.62     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dummy = []\n",
    "#######################################################################\n",
    "print \"#Naive Bayes with binary relevance\"\n",
    "matindex +=1\n",
    "resultantMatrix.append([])\n",
    "resultantMatrix[matindex].append(\"MultinomialNB Binary Relevance\")\n",
    "for classes in categories:\n",
    "    print 'Processing',classes\n",
    "    y = train_df[classes]\n",
    "    Z = Zlist[classes]\n",
    "    #logreg.fit(train_vec, y)\n",
    "    model = MultinomialNB()\n",
    "    model.fit(train_vec, y)  \n",
    "    #y_pred_X = logreg.predict(test_vec)\n",
    "    y_pred_X= model.predict(test_vec)\n",
    "    #dummy.append(y_pred_X[0])\n",
    "    accuracy=accuracy_score(Z, y_pred_X)\n",
    "    print 'Training accuracy :',accuracy\n",
    "    resultantMatrix[matindex].append(accuracy)\n",
    "    mett=metrics.classification_report(Z,y_pred_X)\n",
    "    print mett\n",
    "    #test_y_prob = model.predict_proba(test_vec)[:,1]\n",
    "    #dummy.append(test_y_prob)\n",
    "#print dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Logistic regression with classifier chain\n",
      "Processing toxic\n",
      "Training accuracy : 0.9238644534058582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     57888\n",
      "           1       0.58      0.75      0.65      6090\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     63978\n",
      "   macro avg       0.77      0.85      0.80     63978\n",
      "weighted avg       0.93      0.92      0.93     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4001)\n",
      "Shape of test_train_vec is now (63978, 4001)\n",
      "Processing severe_toxic\n",
      "Training accuracy : 0.9923411172590578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63611\n",
      "           1       0.34      0.35      0.34       367\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.67      0.67      0.67     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4002)\n",
      "Shape of test_train_vec is now (63978, 4002)\n",
      "Processing obscene\n",
      "Training accuracy : 0.9580793397730469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     60287\n",
      "           1       0.62      0.69      0.66      3691\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     63978\n",
      "   macro avg       0.80      0.83      0.82     63978\n",
      "weighted avg       0.96      0.96      0.96     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4003)\n",
      "Shape of test_train_vec is now (63978, 4003)\n",
      "Processing threat\n",
      "Training accuracy : 0.9958735815436557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63767\n",
      "           1       0.37      0.34      0.35       211\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     63978\n",
      "   macro avg       0.68      0.67      0.68     63978\n",
      "weighted avg       1.00      1.00      1.00     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4004)\n",
      "Shape of test_train_vec is now (63978, 4004)\n",
      "Processing insult\n",
      "Training accuracy : 0.9532808152802525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     60551\n",
      "           1       0.56      0.61      0.58      3427\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     63978\n",
      "   macro avg       0.77      0.79      0.78     63978\n",
      "weighted avg       0.96      0.95      0.95     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4005)\n",
      "Shape of test_train_vec is now (63978, 4005)\n",
      "Processing identity_hate\n",
      "Training accuracy : 0.9897308449779612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     63266\n",
      "           1       0.56      0.38      0.45       712\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.77      0.69      0.72     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4006)\n",
      "Shape of test_train_vec is now (63978, 4006)\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "print \"# Logistic regression with classifier chain\"\n",
    "\n",
    "matindex +=1\n",
    "resultantMatrix.append([])\n",
    "resultantMatrix[matindex].append(\"Logistic Regression Classifier Chain\")\n",
    "test_vec_chain = copy.deepcopy(test_vec)\n",
    "train_vec_chain = copy.deepcopy(train_vec)\n",
    "for classes in categories:\n",
    "    print 'Processing',classes\n",
    "    y = train_df[classes]\n",
    "    Z = Zlist[classes]\n",
    "    #model = MultinomialNB()\n",
    "    #logreg.fit(train_vec, y)\n",
    "    logreg.fit(train_vec_chain, y)  \n",
    "    y_pred_X = logreg.predict(test_vec_chain)\n",
    "    #y_pred_X= model.predict(test_vec_chain)\n",
    "    accuracy=accuracy_score(Z, y_pred_X)\n",
    "    print 'Training accuracy :',accuracy\n",
    "    resultantMatrix[matindex].append(accuracy)\n",
    "    mett=metrics.classification_report(Z,y_pred_X)\n",
    "    print mett    \n",
    "    #test_y=logreg.predict(test_vec)\n",
    "    #test_y_prob = model.predict_proba(test_vec)[:,1]\n",
    "    train_vec_chain = add_feature(train_vec_chain, y)\n",
    "    print('Shape of train_vec is now {}'.format(train_vec_chain.shape))\n",
    "    # chain current label predictions to test_train_vec\n",
    "    test_vec_chain = add_feature(test_vec_chain, y_pred_X)\n",
    "    print('Shape of test_train_vec is now {}'.format(test_vec_chain.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Naive Bayes with classifier chain\n",
      "Processing toxic\n",
      "Training accuracy : 0.9346025196161181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     57888\n",
      "           1       0.69      0.56      0.62      6090\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     63978\n",
      "   macro avg       0.82      0.77      0.79     63978\n",
      "weighted avg       0.93      0.93      0.93     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4001)\n",
      "Shape of test_train_vec is now (63978, 4001)\n",
      "Processing severe_toxic\n",
      "Training accuracy : 0.9841039107193098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     63611\n",
      "           1       0.22      0.70      0.34       367\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     63978\n",
      "   macro avg       0.61      0.84      0.66     63978\n",
      "weighted avg       0.99      0.98      0.99     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4002)\n",
      "Shape of test_train_vec is now (63978, 4002)\n",
      "Processing obscene\n",
      "Training accuracy : 0.9479039669886523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     60287\n",
      "           1       0.54      0.70      0.61      3691\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     63978\n",
      "   macro avg       0.76      0.83      0.79     63978\n",
      "weighted avg       0.96      0.95      0.95     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4003)\n",
      "Shape of test_train_vec is now (63978, 4003)\n",
      "Processing threat\n",
      "Training accuracy : 0.987511332020382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     63767\n",
      "           1       0.11      0.41      0.18       211\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.56      0.70      0.59     63978\n",
      "weighted avg       1.00      0.99      0.99     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4004)\n",
      "Shape of test_train_vec is now (63978, 4004)\n",
      "Processing insult\n",
      "Training accuracy : 0.9424958579511707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     60551\n",
      "           1       0.47      0.67      0.55      3427\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     63978\n",
      "   macro avg       0.73      0.81      0.76     63978\n",
      "weighted avg       0.95      0.94      0.95     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4005)\n",
      "Shape of test_train_vec is now (63978, 4005)\n",
      "Processing identity_hate\n",
      "Training accuracy : 0.9345868892431773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     63266\n",
      "           1       0.12      0.74      0.20       712\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     63978\n",
      "   macro avg       0.56      0.84      0.58     63978\n",
      "weighted avg       0.99      0.93      0.96     63978\n",
      "\n",
      "Shape of train_vec is now (159571, 4006)\n",
      "Shape of test_train_vec is now (63978, 4006)\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "print \"#Naive Bayes with classifier chain\"\n",
    "matindex +=1\n",
    "resultantMatrix.append([])\n",
    "resultantMatrix[matindex].append(\"MultinomialNB Classifier Chain\")\n",
    "test_vec_chain = copy.deepcopy(test_vec)\n",
    "train_vec_chain = copy.deepcopy(train_vec)\n",
    "for classes in categories:\n",
    "    print 'Processing',classes\n",
    "    y = train_df[classes]\n",
    "    Z = Zlist[classes]\n",
    "    nbmodel.fit(train_vec_chain, y)  \n",
    "    y_pred_X= nbmodel.predict(test_vec_chain)\n",
    "    accuracy=accuracy_score(Z, y_pred_X)\n",
    "    print 'Training accuracy :',accuracy\n",
    "    resultantMatrix[matindex].append(accuracy)\n",
    "    mett=metrics.classification_report(Z,y_pred_X)\n",
    "    print mett    \n",
    "    train_vec_chain = add_feature(train_vec_chain, y)\n",
    "    print('Shape of train_vec is now {}'.format(train_vec_chain.shape))\n",
    "    # chain current label predictions to test_train_vec\n",
    "    test_vec_chain = add_feature(test_vec_chain, y_pred_X)\n",
    "    print('Shape of test_train_vec is now {}'.format(test_vec_chain.shape))\n",
    "#######################################################################    \n",
    "import csv\n",
    "with open(\"graph.csv\", 'w') as writeFile:\n",
    "    writer = csv.DictWriter(writeFile, fieldnames=resultantMatrix[0])\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(resultantMatrix[0])\n",
    "    for row in range(1,len(resultantMatrix)):\n",
    "        roww = []\n",
    "        roww.append(resultantMatrix[row][0])\n",
    "        val = 0.0\n",
    "        for j in range(1,len(resultantMatrix[row])):\n",
    "            val += resultantMatrix[row][j]\n",
    "        roww.append(val / (len(resultantMatrix[row]) - 1))\n",
    "        writer.writerow(roww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print resultantMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([np.array([1,2,3]),np.array([7,8,9])])\n",
    "B = np.array([np.array([4,5,6]),np.array([10,11,12])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "[ 7  8  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(A)):\n",
    "    print np.concatenate((A[i],B[i]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], 4, 5]\n"
     ]
    }
   ],
   "source": [
    "XX = [[1],[2]]\n",
    "ZZ = [4,5]\n",
    "print XX + ZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]]\n"
     ]
    }
   ],
   "source": [
    "print add_feature(XX,ZZ).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print add_feature(XX,ZZ)[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
